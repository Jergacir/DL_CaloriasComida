{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc47f52",
   "metadata": {},
   "source": [
    "**Modelo de ClasificaciÃ³n con ResNet50 - Ejecutado en Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b9029",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CELDA 1: Verificar dataset\n",
    "import os\n",
    "\n",
    "# Ver estructura\n",
    "print(\"ğŸ“ Contenido del dataset:\")\n",
    "!ls -lh /kaggle/input/food-101/food-101/food-101/\n",
    "\n",
    "print(\"\\nğŸ“Š Carpetas principales:\")\n",
    "!ls /kaggle/input/food-101/food-101/food-101/images/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fde1ce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 2: Imports y configuraciÃ³n\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Verificar GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ”¥ Dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "BATCH_SIZE = 64  # Ajustar segÃºn VRAM\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_WORKERS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218bde1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 3: Split 70/15/15\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Food101Dataset(Dataset):\n",
    "    \"\"\"Dataset para Food-101\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Preparar datos con split 70/15/15\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“‚ Preparando dataset Food-101...\\n\")\n",
    "\n",
    "DATA_PATH = '/kaggle/input/food-101/food-101/food-101'\n",
    "IMAGES_PATH = os.path.join(DATA_PATH, 'images')\n",
    "\n",
    "# Obtener clases\n",
    "classes = sorted([d for d in os.listdir(IMAGES_PATH) \n",
    "                 if os.path.isdir(os.path.join(IMAGES_PATH, d))])\n",
    "\n",
    "print(f\"âœ“ Clases encontradas: {len(classes)}\")\n",
    "\n",
    "# Mapeo clase -> Ã­ndice\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "\n",
    "# Recolectar paths e labels\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"\\nğŸ“Š Escaneando imÃ¡genes...\")\n",
    "for cls in tqdm(classes):\n",
    "    cls_path = os.path.join(IMAGES_PATH, cls)\n",
    "    images = glob.glob(os.path.join(cls_path, '*.jpg'))\n",
    "    \n",
    "    all_image_paths.extend(images)\n",
    "    all_labels.extend([class_to_idx[cls]] * len(images))\n",
    "\n",
    "print(f\"\\nâœ“ Total imÃ¡genes: {len(all_image_paths)}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Split 70/15/15: Train/Val/Test\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nğŸ”€ Dividiendo dataset (70% train, 15% val, 15% test)...\")\n",
    "\n",
    "# Primero: 70% train, 30% temp (val+test)\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    all_image_paths, \n",
    "    all_labels,\n",
    "    test_size=0.30,      # 30% para val+test\n",
    "    random_state=42,\n",
    "    stratify=all_labels\n",
    ")\n",
    "\n",
    "# Segundo: dividir temp en 50/50 (15% val, 15% test)\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths,\n",
    "    temp_labels,\n",
    "    test_size=0.50,      # 50% de 30% = 15% total\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "# Verificar proporciones\n",
    "total = len(all_image_paths)\n",
    "print(f\"\\nğŸ“Š DistribuciÃ³n final:\")\n",
    "print(f\"   Train: {len(train_paths):,} ({100*len(train_paths)/total:.1f}%)\")\n",
    "print(f\"   Val:   {len(val_paths):,} ({100*len(val_paths)/total:.1f}%)\")\n",
    "print(f\"   Test:  {len(test_paths):,} ({100*len(test_paths)/total:.1f}%)\")\n",
    "\n",
    "# Guardar clases\n",
    "with open('food101_classes.json', 'w') as f:\n",
    "    json.dump(classes, f, indent=4)\n",
    "\n",
    "print(\"\\nâœ“ Clases guardadas en food101_classes.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016228bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 4: Transformaciones (Data Augmentation)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# NormalizaciÃ³n de ImageNet (IMPORTANTE para Transfer Learning)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Train: Con augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(25),  # â† Aumentar de 20 a 25\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # â† MÃ¡s agresivo\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # â† NUEVO: pequeÃ±os shifts\n",
    "    transforms.RandomGrayscale(p=0.1),  # â† NUEVO: ocasionalmente B/N\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15))  # â† NUEVO: random erasing\n",
    "])\n",
    "\n",
    "# Test: Sin augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "print(\"âœ“ Transformaciones definidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba60bdb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 5 ACTUALIZADA: Crear Train/Val/Test Loaders\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“Š Creando datasets y loaders...\\n\")\n",
    "\n",
    "# Crear 3 datasets\n",
    "train_dataset = Food101Dataset(train_paths, train_labels, transform=train_transform)\n",
    "val_dataset = Food101Dataset(val_paths, val_labels, transform=test_transform)\n",
    "test_dataset = Food101Dataset(test_paths, test_labels, transform=test_transform)\n",
    "\n",
    "print(f\"âœ“ Train: {len(train_dataset):,} muestras\")\n",
    "print(f\"âœ“ Val:   {len(val_dataset):,} muestras\")\n",
    "print(f\"âœ“ Test:  {len(test_dataset):,} muestras\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Train batches: {len(train_loader)}\")\n",
    "print(f\"âœ“ Val batches:   {len(val_loader)}\")\n",
    "print(f\"âœ“ Test batches:  {len(test_loader)}\")\n",
    "\n",
    "# Verificar un batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"\\nâœ“ Batch shape: {images.shape}\")\n",
    "print(f\"âœ“ Primer label: {labels[0].item()} -> {classes[labels[0].item()]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8421c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 6: Modelo ResNet50\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class ResNet50Food101(nn.Module):\n",
    "    \"\"\"ResNet50 preentrenado para Food-101\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=101, freeze_base=True):\n",
    "        super(ResNet50Food101, self).__init__()\n",
    "        \n",
    "        # Cargar ResNet50 preentrenado\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Congelar capas base\n",
    "        if freeze_base:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Reemplazar Ãºltima capa\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        \"\"\"Descongela todas las capas para fine-tuning\"\"\"\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "# Crear modelo\n",
    "modelo = ResNet50Food101(num_classes=101, freeze_base=True).to(device)\n",
    "\n",
    "# Contar parÃ¡metros\n",
    "total_params = sum(p.numel() for p in modelo.parameters())\n",
    "trainable_params = sum(p.numel() for p in modelo.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nğŸ“Š Modelo ResNet50:\")\n",
    "print(f\"   ParÃ¡metros totales: {total_params:,}\")\n",
    "print(f\"   ParÃ¡metros entrenables: {trainable_params:,}\")\n",
    "print(f\"   Congelados: {total_params - trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25cbb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 7: Funciones de entrenamiento y evaluaciÃ³n\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Mixup augmentation\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "def train_epoch(modelo, loader, criterion, optimizer, device, use_mixup=True):\n",
    "    \"\"\"Entrena una Ã©poca con Mixup opcional\"\"\"\n",
    "    modelo.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Aplicar Mixup\n",
    "        if use_mixup:\n",
    "            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = modelo(images)\n",
    "        \n",
    "        # Loss con Mixup\n",
    "        if use_mixup:\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(modelo.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Accuracy: con Mixup usamos la etiqueta dominante (lam)\n",
    "        if use_mixup:\n",
    "            correct += (lam * (predicted == labels_a).float().sum().item() + \n",
    "                       (1 - lam) * (predicted == labels_b).float().sum().item())\n",
    "        else:\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "            'acc': f'{100*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(modelo, loader, criterion, device):\n",
    "    \"\"\"EvalÃºa el modelo (sin Mixup)\"\"\"\n",
    "    modelo.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Evaluating')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = modelo(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "                'acc': f'{100*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Al final de CELDA 7 (opcional)\n",
    "print(\"\\nâœ… Funciones definidas correctamente:\")\n",
    "print(f\"   - mixup_data()\")\n",
    "print(f\"   - mixup_criterion()\")\n",
    "print(f\"   - train_epoch() con Mixup\")\n",
    "print(f\"   - evaluate()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519be0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 8 MEJORADA: FASE 1 con Early Stopping\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸš€ FASE 1: Entrenando capas FC (base congelada)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Loss y Optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.2)  # â† Era 0.1, aumentar\n",
    "optimizer = optim.AdamW(modelo.resnet.fc.parameters(), lr=LEARNING_RATE, weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "\n",
    "# Historial\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': []\n",
    "}\n",
    "\n",
    "# âœ… EARLY STOPPING\n",
    "mejor_acc = 0.0\n",
    "FASE1_EPOCHS = 50  # â† Ã‰pocas mÃ¡ximas aumentadas\n",
    "patience = 10       # â† Parar si no mejora en 7 Ã©pocas\n",
    "epocas_sin_mejora = 0\n",
    "\n",
    "for epoch in range(FASE1_EPOCHS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Ã‰poca {epoch+1}/{FASE1_EPOCHS} [FASE 1]\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Entrenar\n",
    "    train_loss, train_acc = train_epoch(modelo, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Evaluar\n",
    "    val_loss, val_acc = evaluate(modelo, val_loader, criterion, device)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Guardar historial\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Resumen\n",
    "    print(f\"\\nğŸ“Š Resultados Ã‰poca {epoch+1}:\")\n",
    "    print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "    print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
    "    print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # âœ… Verificar mejora\n",
    "    if val_acc > mejor_acc:\n",
    "        mejor_acc = val_acc\n",
    "        epocas_sin_mejora = 0  # Reset contador\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': modelo.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'classes': classes\n",
    "        }, 'resnet50_food101_fase1.pth')\n",
    "        print(f\"   âœ… Mejor modelo guardado (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        epocas_sin_mejora += 1\n",
    "        print(f\"   â¸ï¸  Sin mejora ({epocas_sin_mejora}/{patience} Ã©pocas)\")\n",
    "    \n",
    "    # âœ… EARLY STOPPING: Detener si no mejora\n",
    "    if epocas_sin_mejora >= patience:\n",
    "        print(f\"\\nğŸ›‘ EARLY STOPPING: No mejora en {patience} Ã©pocas\")\n",
    "        print(f\"   Mejor Val Acc: {mejor_acc:.2f}% (Ã‰poca {epoch - patience + 1})\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nâœ… FASE 1 COMPLETADA. Mejor Val Acc: {mejor_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66217486",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 9: FASE 2 con Early Stopping\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ FASE 2: Fine-tuning completo\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Descongelar modelo\n",
    "modelo.unfreeze()\n",
    "\n",
    "FASE2_EPOCHS = 56  # â† Ã‰pocas mÃ¡ximas aumentadas\n",
    "\n",
    "# Nuevo optimizer\n",
    "optimizer = optim.AdamW(modelo.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=FASE2_EPOCHS)  # Mejor que ReduceLROnPlateau\n",
    "\n",
    "# âœ… EARLY STOPPING\n",
    "patience = 10      # â† Parar si no mejora en 10 Ã©pocas\n",
    "epocas_sin_mejora = 0\n",
    "\n",
    "for epoch in range(FASE2_EPOCHS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Ã‰poca {epoch+1}/{FASE2_EPOCHS} [FASE 2]\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Entrenar\n",
    "    train_loss, train_acc = train_epoch(modelo, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Evaluar\n",
    "    val_loss, val_acc = evaluate(modelo, val_loader, criterion, device)\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Guardar historial\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Resumen\n",
    "    print(f\"\\nğŸ“Š Resultados Ã‰poca {FASE1_EPOCHS + epoch + 1}:\")  # âœ… Ã‰poca total correcta\n",
    "    print(f\"   Train: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "    print(f\"   Val:   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
    "    print(f\"   LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # âœ… Verificar mejora\n",
    "    if val_acc > mejor_acc:\n",
    "        mejor_acc = val_acc\n",
    "        epocas_sin_mejora = 0  # Reset contador\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch + FASE1_EPOCHS,\n",
    "            'model_state_dict': modelo.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'classes': classes\n",
    "        }, 'resnet50_food101_best.pth')\n",
    "        print(f\"   âœ… Mejor modelo guardado (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        epocas_sin_mejora += 1\n",
    "        print(f\"   â¸ï¸  Sin mejora ({epocas_sin_mejora}/{patience} Ã©pocas)\")\n",
    "\n",
    "    # GUARDA HISTORIAL DESPUÃ‰S DE CADA Ã‰POCA â¬‡ï¸\n",
    "    with open('training_history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "        \n",
    "    # âœ… EARLY STOPPING\n",
    "    if epocas_sin_mejora >= patience:\n",
    "        print(f\"\\nğŸ›‘ EARLY STOPPING: No mejora en {patience} Ã©pocas\")\n",
    "        print(f\"   Mejor Val Acc: {mejor_acc:.2f}%\")\n",
    "        break\n",
    "\n",
    "# Guardar modelo final\n",
    "torch.save({\n",
    "    'model_state_dict': modelo.state_dict(),\n",
    "    'val_acc': val_acc,\n",
    "    'classes': classes\n",
    "}, 'resnet50_food101_final.pth')\n",
    "\n",
    "# Guardar historial\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "print(f\"\\nâœ… ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"   Mejor Val Accuracy: {mejor_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bbe55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 10: Visualizar curvas\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)  # âœ… Cambiar a 'val_loss'\n",
    "axes[0].axvline(x=FASE1_EPOCHS, color='red', linestyle='--', label='Fase 2 inicio')\n",
    "axes[0].set_xlabel('Ã‰poca', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Loss durante Entrenamiento', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Acc', linewidth=2)\n",
    "axes[1].plot(history['val_acc'], label='Val Acc', linewidth=2)    # âœ… Cambiar a 'val_acc'\n",
    "axes[1].axvline(x=FASE1_EPOCHS, color='red', linestyle='--', label='Fase 2 inicio')\n",
    "axes[1].axhline(y=mejor_acc, color='green', linestyle='--', label=f'Mejor: {mejor_acc:.2f}%')\n",
    "axes[1].set_xlabel('Ã‰poca', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Accuracy durante Entrenamiento', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ GrÃ¡ficas guardadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46142126",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 11: EvaluaciÃ³n final en TEST\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ EVALUACIÃ“N FINAL EN TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Cargar mejor modelo\n",
    "checkpoint = torch.load('resnet50_food101_best.pth')\n",
    "modelo.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluar en test\n",
    "test_loss, test_acc = evaluate(modelo, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\nğŸ“Š RESULTADOS FINALES:\")\n",
    "print(f\"   Mejor Val Acc:  {mejor_acc:.2f}%\")\n",
    "print(f\"   Test Acc:       {test_acc:.2f}%\")\n",
    "print(f\"   Diferencia:     {abs(test_acc - mejor_acc):.2f}%\")\n",
    "\n",
    "if abs(test_acc - mejor_acc) < 3:\n",
    "    print(\"\\nâœ… Modelo generaliza bien (diferencia < 3%)\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Posible overfitting (diferencia > 3%)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
